{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02. Tensors - The Complete Guide\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/gaurav-redhat/pytorch_tutorial/blob/main/02_tensors/demo.ipynb)\n",
        "\n",
        "This notebook covers **everything** about PyTorch tensors - from creation to linear algebra.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Tensor Creation - Every Method\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# From Python data\n",
        "x = torch.tensor([1, 2, 3])\n",
        "print(f\"From list: {x}, dtype: {x.dtype}\")\n",
        "\n",
        "x = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n",
        "print(f\"2D float: \\n{x}\")\n",
        "\n",
        "# Zeros and Ones\n",
        "print(f\"\\nZeros (3x4):\\n{torch.zeros(3, 4)}\")\n",
        "print(f\"\\nOnes (2x3):\\n{torch.ones(2, 3)}\")\n",
        "print(f\"\\nFull (2x3, value=7):\\n{torch.full((2, 3), 7.0)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Random tensors\n",
        "torch.manual_seed(42)  # For reproducibility\n",
        "\n",
        "print(f\"Uniform [0,1): {torch.rand(3)}\")\n",
        "print(f\"Normal (0,1): {torch.randn(3)}\")\n",
        "print(f\"Random integers [0,10): {torch.randint(0, 10, (3,))}\")\n",
        "print(f\"Random permutation: {torch.randperm(5)}\")\n",
        "\n",
        "# Sequences\n",
        "print(f\"\\narange(0, 10): {torch.arange(0, 10)}\")\n",
        "print(f\"arange(0, 10, 2): {torch.arange(0, 10, 2)}\")\n",
        "print(f\"linspace(0, 1, 5): {torch.linspace(0, 1, 5)}\")\n",
        "print(f\"logspace(0, 2, 3): {torch.logspace(0, 2, 3)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Special matrices\n",
        "print(f\"Identity (3x3):\\n{torch.eye(3)}\")\n",
        "print(f\"\\nDiagonal:\\n{torch.diag(torch.tensor([1, 2, 3]))}\")\n",
        "print(f\"\\nLower triangular:\\n{torch.tril(torch.ones(3, 3))}\")\n",
        "print(f\"\\nUpper triangular:\\n{torch.triu(torch.ones(3, 3))}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. NumPy Bridge - Full Interoperability\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# NumPy to PyTorch\n",
        "np_array = np.array([1.0, 2.0, 3.0])\n",
        "tensor_shared = torch.from_numpy(np_array)  # Shares memory!\n",
        "tensor_copy = torch.tensor(np_array)        # Copies data\n",
        "\n",
        "print(f\"NumPy array: {np_array}\")\n",
        "print(f\"Tensor (shared): {tensor_shared}\")\n",
        "print(f\"Tensor (copy): {tensor_copy}\")\n",
        "\n",
        "# Shared memory demonstration\n",
        "np_array[0] = 100\n",
        "print(f\"\\nAfter changing np_array[0] to 100:\")\n",
        "print(f\"  np_array: {np_array}\")\n",
        "print(f\"  tensor_shared: {tensor_shared}\")  # Also changed!\n",
        "print(f\"  tensor_copy: {tensor_copy}\")      # Unchanged\n",
        "\n",
        "# PyTorch to NumPy\n",
        "tensor = torch.tensor([1.0, 2.0, 3.0])\n",
        "back_to_numpy = tensor.numpy()\n",
        "print(f\"\\nTensor to NumPy: {back_to_numpy}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Tensor Operations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Arithmetic\n",
        "a = torch.tensor([1.0, 2.0, 3.0])\n",
        "b = torch.tensor([4.0, 5.0, 6.0])\n",
        "\n",
        "print(f\"a = {a}, b = {b}\")\n",
        "print(f\"a + b = {a + b}\")\n",
        "print(f\"a - b = {a - b}\")\n",
        "print(f\"a * b = {a * b}\")  # Element-wise\n",
        "print(f\"a / b = {a / b}\")\n",
        "print(f\"a ** 2 = {a ** 2}\")\n",
        "\n",
        "# In-place operations\n",
        "x = torch.tensor([1.0, 2.0, 3.0])\n",
        "print(f\"\\nOriginal: {x}\")\n",
        "x.add_(1)\n",
        "print(f\"After add_(1): {x}\")\n",
        "x.mul_(2)\n",
        "print(f\"After mul_(2): {x}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Math functions\n",
        "x = torch.tensor([1.0, 4.0, 9.0])\n",
        "print(f\"x = {x}\")\n",
        "print(f\"sqrt: {torch.sqrt(x)}\")\n",
        "print(f\"exp: {torch.exp(x)}\")\n",
        "print(f\"log: {torch.log(x)}\")\n",
        "print(f\"abs: {torch.abs(torch.tensor([-1, 2, -3]))}\")\n",
        "\n",
        "# Trigonometry\n",
        "angles = torch.tensor([0, np.pi/2, np.pi])\n",
        "print(f\"\\nAngles: {angles}\")\n",
        "print(f\"sin: {torch.sin(angles)}\")\n",
        "print(f\"cos: {torch.cos(angles)}\")\n",
        "\n",
        "# Rounding\n",
        "y = torch.tensor([1.2, 2.7, 3.5])\n",
        "print(f\"\\nRounding y={y}:\")\n",
        "print(f\"floor: {torch.floor(y)}\")\n",
        "print(f\"ceil: {torch.ceil(y)}\")\n",
        "print(f\"round: {torch.round(y)}\")\n",
        "print(f\"clamp(0,2): {torch.clamp(y, 0, 2)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reduction operations\n",
        "x = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
        "print(f\"Tensor:\\n{x}\\n\")\n",
        "\n",
        "print(f\"sum: {x.sum()}\")\n",
        "print(f\"mean: {x.mean()}\")\n",
        "print(f\"std: {x.std()}\")\n",
        "print(f\"min: {x.min()}, argmin: {x.argmin()}\")\n",
        "print(f\"max: {x.max()}, argmax: {x.argmax()}\")\n",
        "\n",
        "print(f\"\\nsum(dim=0): {x.sum(dim=0)}\")  # Sum columns\n",
        "print(f\"sum(dim=1): {x.sum(dim=1)}\")    # Sum rows\n",
        "print(f\"mean(dim=1): {x.mean(dim=1)}\")  # Mean of each row\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparison operations\n",
        "a = torch.tensor([1, 2, 3])\n",
        "b = torch.tensor([2, 2, 2])\n",
        "print(f\"a = {a}, b = {b}\")\n",
        "\n",
        "print(f\"a > b: {a > b}\")\n",
        "print(f\"a == b: {a == b}\")\n",
        "print(f\"all(a > 0): {torch.all(a > 0)}\")\n",
        "print(f\"any(a > 2): {torch.any(a > 2)}\")\n",
        "print(f\"maximum(a, b): {torch.maximum(a, b)}\")\n",
        "print(f\"minimum(a, b): {torch.minimum(a, b)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Linear Algebra\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Matrix multiplication\n",
        "A = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
        "B = torch.tensor([[5.0, 6.0], [7.0, 8.0]])\n",
        "\n",
        "print(f\"A:\\n{A}\\nB:\\n{B}\\n\")\n",
        "\n",
        "# Three ways to multiply\n",
        "print(f\"A @ B:\\n{A @ B}\\n\")\n",
        "print(f\"torch.mm(A, B):\\n{torch.mm(A, B)}\\n\")\n",
        "print(f\"torch.matmul(A, B):\\n{torch.matmul(A, B)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Matrix-vector multiplication\n",
        "A = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
        "x = torch.tensor([1.0, 2.0, 3.0])\n",
        "print(f\"A (2x3):\\n{A}\\nx (3,): {x}\\n\")\n",
        "print(f\"A @ x: {A @ x}\")  # (2,)\n",
        "\n",
        "# Dot and outer product\n",
        "a = torch.tensor([1.0, 2.0, 3.0])\n",
        "b = torch.tensor([4.0, 5.0, 6.0])\n",
        "print(f\"\\nDot product: {torch.dot(a, b)}\")\n",
        "print(f\"Outer product:\\n{torch.outer(a, b)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Matrix properties\n",
        "A = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
        "print(f\"A:\\n{A}\\n\")\n",
        "print(f\"Transpose:\\n{A.T}\\n\")\n",
        "print(f\"Trace: {torch.trace(A)}\")\n",
        "print(f\"Determinant: {torch.linalg.det(A)}\")\n",
        "print(f\"Rank: {torch.linalg.matrix_rank(A)}\")\n",
        "print(f\"Frobenius norm: {torch.linalg.norm(A)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Matrix inverse\n",
        "A = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
        "A_inv = torch.linalg.inv(A)\n",
        "print(f\"A:\\n{A}\\nA inverse:\\n{A_inv}\\n\")\n",
        "print(f\"A @ A_inv (should be identity):\\n{A @ A_inv}\")\n",
        "\n",
        "# Eigenvalues\n",
        "eigenvalues, eigenvectors = torch.linalg.eig(A)\n",
        "print(f\"\\nEigenvalues: {eigenvalues}\")\n",
        "\n",
        "# SVD\n",
        "U, S, Vh = torch.linalg.svd(A)\n",
        "print(f\"\\nSVD - Singular values: {S}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Solve linear system Ax = b\n",
        "A = torch.tensor([[2.0, 1.0], [1.0, 3.0]])\n",
        "b = torch.tensor([4.0, 5.0])\n",
        "\n",
        "x = torch.linalg.solve(A, b)\n",
        "print(f\"A:\\n{A}\\nb: {b}\\n\")\n",
        "print(f\"Solution x: {x}\")\n",
        "print(f\"Verification A @ x: {A @ x}\")  # Should equal b\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Reshaping & Indexing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View and reshape\n",
        "x = torch.arange(12)\n",
        "print(f\"Original (12,): {x}\\n\")\n",
        "print(f\"view(3, 4):\\n{x.view(3, 4)}\\n\")\n",
        "print(f\"view(4, 3):\\n{x.view(4, 3)}\\n\")\n",
        "print(f\"view(2, 2, 3):\\n{x.view(2, 2, 3)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Squeeze and unsqueeze\n",
        "x = torch.randn(1, 3, 1, 4)\n",
        "print(f\"Original shape: {x.shape}\")\n",
        "print(f\"squeeze(): {x.squeeze().shape}\")     # Remove all 1s\n",
        "print(f\"squeeze(0): {x.squeeze(0).shape}\")   # Remove dim 0\n",
        "print(f\"squeeze(2): {x.squeeze(2).shape}\")   # Remove dim 2\n",
        "\n",
        "y = torch.randn(3, 4)\n",
        "print(f\"\\n(3,4) + unsqueeze(0): {y.unsqueeze(0).shape}\")\n",
        "print(f\"(3,4) + unsqueeze(1): {y.unsqueeze(1).shape}\")\n",
        "print(f\"(3,4) + unsqueeze(-1): {y.unsqueeze(-1).shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Concatenate and stack\n",
        "a = torch.tensor([[1, 2], [3, 4]])\n",
        "b = torch.tensor([[5, 6], [7, 8]])\n",
        "print(f\"a:\\n{a}\\nb:\\n{b}\\n\")\n",
        "\n",
        "print(f\"cat dim=0 (vertical):\\n{torch.cat([a, b], dim=0)}\\n\")\n",
        "print(f\"cat dim=1 (horizontal):\\n{torch.cat([a, b], dim=1)}\\n\")\n",
        "print(f\"stack dim=0:\\n{torch.stack([a, b], dim=0)}\")\n",
        "print(f\"Stack shape: {torch.stack([a, b], dim=0).shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Indexing\n",
        "x = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n",
        "print(f\"x:\\n{x}\\n\")\n",
        "\n",
        "print(f\"x[0]: {x[0]}\")\n",
        "print(f\"x[0, 1]: {x[0, 1]}\")\n",
        "print(f\"x[0:2]:\\n{x[0:2]}\")\n",
        "print(f\"x[:, 1:3]:\\n{x[:, 1:3]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fancy and boolean indexing\n",
        "x = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n",
        "\n",
        "indices = torch.tensor([0, 2])\n",
        "print(f\"x[indices] (rows 0 and 2):\\n{x[indices]}\\n\")\n",
        "\n",
        "# Boolean mask\n",
        "mask = x > 5\n",
        "print(f\"x > 5:\\n{mask}\\n\")\n",
        "print(f\"Values where x > 5: {x[mask]}\")\n",
        "\n",
        "# torch.where\n",
        "result = torch.where(x > 5, x, torch.zeros_like(x))\n",
        "print(f\"\\nwhere(x > 5, x, 0):\\n{result}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Broadcasting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Broadcasting examples\n",
        "a = torch.tensor([[1, 2, 3], [4, 5, 6]])  # (2, 3)\n",
        "b = torch.tensor([10, 20, 30])             # (3,)\n",
        "print(f\"a (2x3):\\n{a}\")\n",
        "print(f\"b (3,): {b}\\n\")\n",
        "print(f\"a + b (broadcasts!):\\n{a + b}\")\n",
        "\n",
        "# Different shapes\n",
        "a = torch.tensor([[1], [2], [3]])  # (3, 1)\n",
        "b = torch.tensor([10, 20, 30, 40]) # (4,)\n",
        "print(f\"\\na (3x1):\\n{a}\")\n",
        "print(f\"b (4,): {b}\\n\")\n",
        "print(f\"a + b (3x1 + 1x4 = 3x4):\\n{a + b}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Memory & Device Management\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Contiguous memory\n",
        "x = torch.randn(3, 4)\n",
        "y = x.T\n",
        "print(f\"x is contiguous: {x.is_contiguous()}\")\n",
        "print(f\"x.T is contiguous: {y.is_contiguous()}\")\n",
        "\n",
        "# view requires contiguous, reshape doesn't\n",
        "try:\n",
        "    y.view(-1)\n",
        "except RuntimeError as e:\n",
        "    print(f\"\\nError with view on non-contiguous: {e}\")\n",
        "\n",
        "print(f\"reshape works: {y.reshape(-1).shape}\")\n",
        "print(f\"contiguous + view works: {y.contiguous().view(-1).shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Device management (GPU)\n",
        "x = torch.randn(3, 4)\n",
        "print(f\"Device: {x.device}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    x_gpu = x.to('cuda')\n",
        "    print(f\"After .to('cuda'): {x_gpu.device}\")\n",
        "    x_cpu = x_gpu.cpu()\n",
        "    print(f\"After .cpu(): {x_cpu.device}\")\n",
        "    \n",
        "    # Create directly on GPU\n",
        "    y = torch.randn(3, 4, device='cuda')\n",
        "    print(f\"Created on GPU: {y.device}\")\n",
        "else:\n",
        "    print(\"CUDA not available - running on CPU\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone vs reference\n",
        "x = torch.tensor([1, 2, 3])\n",
        "\n",
        "# Assignment is a reference\n",
        "y = x\n",
        "y[0] = 100\n",
        "print(f\"After y = x and y[0] = 100: x = {x}\")\n",
        "\n",
        "# Clone creates a copy\n",
        "x = torch.tensor([1, 2, 3])\n",
        "y = x.clone()\n",
        "y[0] = 100\n",
        "print(f\"After y = x.clone() and y[0] = 100: x = {x}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "| Category | Key Functions |\n",
        "|----------|---------------|\n",
        "| **Creation** | `tensor()`, `zeros()`, `ones()`, `randn()`, `arange()`, `linspace()`, `eye()` |\n",
        "| **NumPy** | `from_numpy()`, `.numpy()` |\n",
        "| **Arithmetic** | `+`, `-`, `*`, `/`, `**`, `.add_()`, `.mul_()` |\n",
        "| **Math** | `sqrt()`, `exp()`, `log()`, `sin()`, `cos()`, `abs()`, `clamp()` |\n",
        "| **Reduction** | `sum()`, `mean()`, `std()`, `min()`, `max()`, `argmax()` |\n",
        "| **Linear Algebra** | `@`, `mm()`, `matmul()`, `linalg.inv()`, `linalg.svd()`, `linalg.eig()`, `linalg.solve()` |\n",
        "| **Reshape** | `view()`, `reshape()`, `squeeze()`, `unsqueeze()`, `flatten()` |\n",
        "| **Combine** | `cat()`, `stack()`, `chunk()`, `split()` |\n",
        "| **Index** | `[]`, `[mask]`, `where()`, `gather()` |\n",
        "\n",
        "---\n",
        "\n",
        "**Next:** [Autograd - Automatic Differentiation](../03_autograd/README.md)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
